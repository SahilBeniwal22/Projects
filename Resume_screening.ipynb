{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLc/SWE3EW19xXBGlc/XaM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SahilBeniwal22/Projects/blob/main/Resume_screening.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pypdf2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQPyJ2-kDXkK",
        "outputId": "00b2e020-bb90-478a-ea91-6b5a1441ef07"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf2\n",
            "Successfully installed pypdf2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Clean text\n",
        "def clean_text(text):\n",
        "    text = re .sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n",
        "    return text.lower()\n",
        "\n",
        "# Extract text from PDF\n",
        "def extract_text_from_pdf(file_path):\n",
        "    reader = PdfReader(file_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return clean_text(text)\n",
        "\n",
        "# Extract text from multiple resumes\n",
        "def extract_text_from_multiple_resumes(file_paths):\n",
        "    resume_texts = {}\n",
        "    for file_path in file_paths:\n",
        "        try:\n",
        "            text = extract_text_from_pdf(file_path)\n",
        "            resume_texts[file_path] = text\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file_path}: {e}\")\n",
        "    return resume_texts\n",
        "\n",
        "# List of resume file paths\n",
        "resume_files = [\n",
        "    \"/content/Resume.pdf\",\n",
        "    \"/content/Aarti_Yadav_resume.pdf\"\n",
        "]\n",
        "\n",
        "# Extract text for all resumes\n",
        "resumes_texts = extract_text_from_multiple_resumes(resume_files)\n",
        "\n",
        "# Display the first 500 characters of each resume's text\n",
        "for file_path, text in resumes_texts.items():\n",
        "    print(f\"\\nFile: {file_path}\")\n",
        "    print(f\"Extracted Text (First 500 Characters): {text[:500]}\")"
      ],
      "metadata": {
        "id": "w6zsYn0_Ct10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ee03cc7-ce54-4cb7-c160-c7ef58a732d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "File: /content/Resume.pdf\n",
            "Extracted Text (First 500 Characters): sahil beniwal gurgaonharyana  91 8586858027 sahilbeny24gmailcom  httpswwwlinkedincominsahilbeniwal22  httpsgithubcomsahilbeniwal22 summary finalyear btech student specializing in aiml with handson experience in python designing rnn and cnn models actively developing skills in data structures and algorithms seeking opportunities for an internship or job in the field skills programming languages  java  python  html5  matlab  sql  dart libraries  frameworks  keras  numpy  pandas  scipy  dialogflow \n",
            "\n",
            "File: /content/Aarti_Yadav_resume.pdf\n",
            "Extracted Text (First 500 Characters): aarti yadav data analyst 91 9667106415 2111aartiyadavgmailcom gurgaonharyana objective passionate and dedicated 3rdyear undergraduate pursuing a bachelors in computer applications proficient in data analysis python and sql with handson experience in projects involving data visualization and trend analysis eager to contribute to organizational growth while enhancing my professional expertise education the northcap university 2022  2025 bachelor of computer applications specialization in mobile ap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predefined list of skills\n",
        "skills_list = [\"python\", \"java\", \"sql\",\"react\",\"javascript\",\"mongodb\"]\n",
        "\n",
        "# Extract skills from text\n",
        "def extract_skills(text, skills_list):\n",
        "    skills_found = [skill for skill in skills_list if skill in text]\n",
        "    return skills_found\n",
        "\n",
        "# Extract skills from multiple resumes\n",
        "def extract_skills_from_multiple_resumes(resumes_texts, skills_list):\n",
        "    skills_summary = {}\n",
        "    for file_path, text in resumes_texts.items():\n",
        "        skills_found = extract_skills(text, skills_list)\n",
        "        skills_summary[file_path] = skills_found\n",
        "    return skills_summary\n",
        "\n",
        "# Example usage with multiple resumes\n",
        "resume_files = [\n",
        "    \"/content/Resume.pdf\",\n",
        "    \"/content/Aarti_Yadav_resume.pdf\",\n",
        "    \"/content/Aarti's Resume-hackerresume (1).pdf\"\n",
        "]\n",
        "\n",
        "# Extract text for all resumes\n",
        "resumes_texts = extract_text_from_multiple_resumes(resume_files)\n",
        "\n",
        "# Extract skills for all resumes\n",
        "skills_summary = extract_skills_from_multiple_resumes(resumes_texts, skills_list)\n",
        "\n",
        "# Display extracted skills for each resume\n",
        "for file_path, skills in skills_summary.items():\n",
        "    print(f\"\\nFile: {file_path}\")\n",
        "    print(f\"Extracted Skills: {skills}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhD7dcJDC_yf",
        "outputId": "f04f19d3-41d1-494c-ed85-4d3842a01618"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading /content/Aarti's Resume-hackerresume (1).pdf: [Errno 2] No such file or directory: \"/content/Aarti's Resume-hackerresume (1).pdf\"\n",
            "\n",
            "File: /content/Resume.pdf\n",
            "Extracted Skills: ['python', 'java', 'sql']\n",
            "\n",
            "File: /content/Aarti_Yadav_resume.pdf\n",
            "Extracted Skills: ['python', 'java', 'sql', 'javascript']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Match resumes to a job description\n",
        "def match_resumes_to_job(resumes, job_description):\n",
        "    # Combine job description and resumes into one list\n",
        "    documents = [job_description] + resumes\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    job_vector = tfidf_matrix[0]\n",
        "    resume_vectors = tfidf_matrix[1:]\n",
        "    similarities = cosine_similarity(job_vector, resume_vectors).flatten()\n",
        "\n",
        "    # Rank resumes by similarity\n",
        "    ranked_indices = similarities.argsort()[::-1]\n",
        "    return ranked_indices, similarities\n",
        "\n",
        "# Example usage\n",
        "job_description = \"Looking for a Python developer with experience in NLP and machine learning.\"\n",
        "\n",
        "# List of resumes\n",
        "resumes = [\n",
        "    extract_text_from_pdf(\"/content/Resume.pdf\"),\n",
        "    extract_text_from_pdf(\"/content/Aarti_Yadav_resume.pdf\")\n",
        "]\n",
        "\n",
        "# Match resumes to the job description\n",
        "ranked_indices, similarities = match_resumes_to_job(resumes, job_description)\n",
        "\n",
        "# Display similarity rankings\n",
        "print(\"Ranking of Resumes Based on Job Description:\")\n",
        "for rank, idx in enumerate(ranked_indices):\n",
        "    print(f\"Rank {rank + 1}: Resume {idx + 1} - Similarity: {similarities[idx]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HUmZDI8DWPu",
        "outputId": "53238ab7-26c7-4fc9-e803-390136406f56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranking of Resumes Based on Job Description:\n",
            "Rank 1: Resume 1 - Similarity: 0.21\n",
            "Rank 2: Resume 2 - Similarity: 0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resume_screening_pipeline(resume_files, job_description, skills_list):\n",
        "    resumes_texts = []\n",
        "\n",
        "    # Step 1: Extract and clean text from all resumes\n",
        "    for file in resume_files:\n",
        "        text = extract_text_from_pdf(file)\n",
        "        resumes_texts.append(text)\n",
        "\n",
        "    # Step 2: Extract skills from resumes\n",
        "    skills_summary = [extract_skills(resume, skills_list) for resume in resumes_texts]\n",
        "\n",
        "    # Step 3: Match resumes to the job description\n",
        "    ranked_indices, similarities = match_resumes_to_job(resumes_texts, job_description)\n",
        "\n",
        "    # Step 4: Compile results\n",
        "    results = []\n",
        "    for rank, idx in enumerate(ranked_indices):\n",
        "        results.append({\n",
        "            \"Rank\": rank + 1,\n",
        "            \"Resume\": resume_files[idx],\n",
        "            \"Similarity\": round(similarities[idx], 2),\n",
        "            \"Skills\": skills_summary[idx]\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# Example usage\n",
        "resume_files = [\n",
        "    \"/content/Resume.pdf\",\n",
        "    \"/content/Aarti_Yadav_resume.pdf\",\n",
        "    # \"/content/Ankur_Resume.pdf\"  # Add more files as needed\n",
        "]\n",
        "\n",
        "# Define the job description and skills list\n",
        "job_description = \"Looking for a Python developer with experience in NLP and machine learning.\"\n",
        "skills_list = [\"python\", \"java\", \"sql\", \"html\", \"css\", \"nlp\", \"machine learning\", \"aws\"]\n",
        "\n",
        "# Run the screening pipeline\n",
        "results = resume_screening_pipeline(resume_files, job_description, skills_list)\n",
        "\n",
        "# Display results\n",
        "for result in results:\n",
        "    print(f\"Rank: {result['Rank']}\")\n",
        "    print(f\"Resume: {result['Resume']}\")\n",
        "    print(f\"Similarity: {result['Similarity']}\")\n",
        "    print(f\"Extracted Skills: {result['Skills']}\")\n",
        "    print(\"-\" * 40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J1mGw8UnhqK",
        "outputId": "0721fb86-b3b8-4cff-c4b7-5a1fdccdb3bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank: 1\n",
            "Resume: /content/Resume.pdf\n",
            "Similarity: 0.21\n",
            "Extracted Skills: ['python', 'java', 'sql', 'html']\n",
            "----------------------------------------\n",
            "Rank: 2\n",
            "Resume: /content/Aarti_Yadav_resume.pdf\n",
            "Similarity: 0.13\n",
            "Extracted Skills: ['python', 'java', 'sql', 'html']\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Riv3oEvn2Hr"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}